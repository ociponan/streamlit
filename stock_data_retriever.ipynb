{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuz+V1liAdIxAQUsZznwzf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ociponan/streamlit/blob/main/stock_data_retriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1PAphr2zR2aq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas_datareader as pdr\n",
        "import datetime as dt\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "from pandas.tseries.frequencies import to_offset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_ticker_file(file=\"./tickers.csv\"):\n",
        "    tickers = pd.read_csv(file)\n",
        "    tickers[\"現在値\"] = tickers[\"現在値\"].replace(\"-\", None)\n",
        "    tickers = tickers.dropna(subset=[\"現在値\"], axis=0).reset_index(drop=True)\n",
        "    tickers = tickers.loc[\n",
        "        (tickers[\"市場\"] == \"東P\") | (tickers[\"市場\"] == \"東S\") |\n",
        "        (tickers[\"市場\"] == \"東G\") | (tickers[\"市場\"] == \"東ETF\") |\n",
        "        (tickers[\"市場\"] == \"東REIT\") | (tickers[\"市場\"] == \"東優\") |\n",
        "        (tickers[\"市場\"] == \"東IF\"), :\n",
        "    ].reset_index(drop=True)\n",
        "    return tickers\n",
        "\n",
        "def _retrieve_data(code, start=None, end=None, src=\"yfinance\"):\n",
        "    if src == \"yfinance\":\n",
        "        if f\"{code}\"[0].isdigit():\n",
        "            ticker = f\"{code}.T\"\n",
        "        else:\n",
        "            ticker = f\"{code}\"\n",
        "        stock = yf.Ticker(ticker)\n",
        "        if start is None:\n",
        "            data = stock.history(period=\"max\").tz_localize(None)\n",
        "        else:\n",
        "            if end is None:\n",
        "                data = stock.history(start=start, end=dt.date.today()).tz_localize(None)\n",
        "            else:\n",
        "                data = stock.history(start=start, end=end + relativedelta(days=1)).tz_localize(None)\n",
        "        # data = yf.download(f\"{ticker}.T\", start=start, end=dt.date.today() + relativedelta(days=1)).tz_localize(None).sort_index()\n",
        "    else:\n",
        "        if f\"{code}\"[0].isdigit():\n",
        "            ticker = f\"{code}.JP\"\n",
        "        else:\n",
        "            ticker = f\"{code}\"\n",
        "        data = pdr.DataReader(ticker, data_source=\"stooq\", start=start).sort_index()\n",
        "    return data\n",
        "\n",
        "def get_stock_price(code, start, end=dt.date.today()+dt.timedelta(days=1)):\n",
        "    if code[0].isdigit():\n",
        "        ticker = f\"{code}.T\"\n",
        "    else:\n",
        "        ticker = code\n",
        "    stock = yf.Ticker(ticker)\n",
        "    if start is not None:\n",
        "        data = stock.history(start=start).tz_localize(None)\n",
        "    else:\n",
        "        data = stock.history(period=\"max\").tz_localize(None)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def read_index_data(filename):\n",
        "    df = pd.read_csv(filename)\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "    df.set_index(\"Date\", inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_resample(df, interval):\n",
        "    if interval.lower() in (\"w\", \"weekly\"):\n",
        "        rdf = df.resample(\"W\").agg({\n",
        "        \"Open\": \"first\", \"High\": \"max\", \"Low\": \"min\",\n",
        "        \"Close\": \"last\", \"Volume\": \"sum\"\n",
        "        })\n",
        "        rdf.index = rdf.index - to_offset(\"2D\")\n",
        "    elif interval.lower() in (\"m\", \"monthly\"):\n",
        "        rdf = df.resample(\"ME\").agg({\n",
        "        \"Open\": \"first\", \"High\": \"max\", \"Low\": \"min\",\n",
        "        \"Close\": \"last\", \"Volume\": \"sum\"\n",
        "        })\n",
        "    elif interval.lower() in (\"d\", \"daily\"):\n",
        "        rdf = df\n",
        "\n",
        "    return rdf"
      ],
      "metadata": {
        "id": "JFXAzPCtR6Ij"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interval = \"Daily\"\n",
        "def _historical_high(ser, window):\n",
        "    return ser.rolling(window=window).max()\n",
        "\n",
        "def _historical_low(ser, window):\n",
        "    return ser.rolling(window=window).min()\n",
        "\n",
        "def _sma(ser, window=9):\n",
        "    sma_series = ser.rolling(window=window).mean()\n",
        "    return sma_series\n",
        "\n",
        "def _rma(ser, period=9):\n",
        "    \"\"\"\n",
        "    Calculate the Relative Moving Average (RMA) of a time series.\n",
        "\n",
        "    Parameters:\n",
        "    series (pd.Series): The input time series.\n",
        "    period (int): The length of the RMA.\n",
        "\n",
        "    Returns:\n",
        "    pd.Series: The RMA of the input time series.\n",
        "    \"\"\"\n",
        "\n",
        "    rma_series = ser.ewm(com=(period-1), min_periods=period).mean()\n",
        "    return rma_series\n",
        "\n",
        "def _ema(ser, span=9):\n",
        "    ema_series = ser.ewm(span=span, min_periods=span, adjust=False).mean()\n",
        "    return ema_series\n",
        "\n",
        "def _multiple_mavs(df, ma_period):\n",
        "    data = pd.DataFrame(index=df.index)\n",
        "    ma_period = sorted(ma_period)\n",
        "    for period in ma_period:\n",
        "        col = f\"ma{period}\"\n",
        "        data[col] = _sma(df[\"Close\"], period)\n",
        "    return data\n",
        "\n",
        "def _mtt_signal(df, ma_period, lookback):\n",
        "    data = _multiple_mavs(df, ma_period)\n",
        "    mav = data.columns\n",
        "\n",
        "    data[\"flg1\"] = (df[\"Close\"] > data[mav[1]]) & (df[\"Close\"] > data[mav[2]])\n",
        "    data[\"flg2\"] = data[mav[1]] > data[mav[2]]\n",
        "    data[\"flg3\"] = data[mav[2]] > data[mav[2]].shift(lookback[0])\n",
        "    data[\"flg4\"] = (data[mav[0]] >= data[mav[1]]) & (data[mav[0]] > data[mav[2]])\n",
        "    data[\"flg5\"] = df[\"Close\"] > data[mav[0]]\n",
        "    data[\"flg6\"] = df[\"Close\"] > (1.25 * _historical_low(df[\"Low\"], lookback[1]))\n",
        "    data[\"flg7\"] = df[\"Close\"] < (1.25 * _historical_high(df[\"High\"], lookback[1]))\n",
        "\n",
        "    data[\"mtt_signal\"] = np.where(\n",
        "        data[\"flg1\"] & data[\"flg2\"] & data[\"flg3\"] & data[\"flg4\"] & data[\"flg5\"] & data[\"flg6\"] & data[\"flg7\"],\n",
        "        1, 0\n",
        "    )\n",
        "    return data.drop(mav, axis=1)\n",
        "\n",
        "def _dorsey_rs(df, interval, numeraire=\"TOPIX\"):\n",
        "    global topix\n",
        "    if numeraire.upper() in (\"TPX\", \"TOPIX\"):\n",
        "        df_m = topix\n",
        "    elif numeraire.upper() in (\"NIKKEI\", \"N225\", \"NIKKEI225\", \"NKX\", \"^N225\", \"^NKX\"):\n",
        "        df_m = read_index_data(\"./n225.csv\")\n",
        "\n",
        "    if interval != \"Daily\":\n",
        "        df_m = get_resample(df_m, interval)\n",
        "\n",
        "    if len(df_m) > len(df):\n",
        "        if type(df.index) is pd.core.indexes.datetimes.DatetimeIndex:\n",
        "            df_m = df_m.loc[df.first_valid_index().date():]\n",
        "        else:\n",
        "            df_m = df_m.loc[min(df[\"Date\"]).date():]\n",
        "    return 100 * df.Close / df_m.Close\n",
        "\n",
        "\n",
        "def _mansfield_rs(df, period, interval, numeraire=\"TOPIX\"):\n",
        "    \"\"\"Calculate Mansfield Relative Strength\n",
        "    period: 200 for daily, 52 for weekly, 12 for monthly\n",
        "    https://x.gd/WWmfn\n",
        "    \"\"\"\n",
        "    global topix\n",
        "    if numeraire.upper() in (\"TPX\", \"TOPIX\"):\n",
        "        df_m = topix\n",
        "    elif numeraire.upper() in (\"NIKKEI\", \"N225\", \"NIKKEI225\", \"NKX\", \"^N225\", \"^NKX\"):\n",
        "        df_m = read_index_data(\"./n225.csv\")\n",
        "\n",
        "    if interval != \"Daily\":\n",
        "        df_m = get_resample(df_m, interval)\n",
        "\n",
        "    d_rs = _dorsey_rs(df, interval, numeraire)\n",
        "    window = min(len(df), period)\n",
        "    return (d_rs / _sma(d_rs, window=window) - 1) * 100\n",
        "\n",
        "def get_relative_performance(df, interval):\n",
        "    length = len(df)\n",
        "    if interval == \"Daily\":\n",
        "        if length > 200:\n",
        "            period = 200\n",
        "        elif length > 100:\n",
        "            period = length\n",
        "        else:\n",
        "            period = 200\n",
        "    elif interval == \"Weekly\":\n",
        "        period = 52\n",
        "    elif interval == \"Monthly\":\n",
        "        period = 12\n",
        "    numeraire = \"TOPIX\"\n",
        "    return _mansfield_rs(df, period, interval, numeraire)\n",
        "\n",
        "\n",
        "def _relative_strength(df, q1, q2, q3, q4):\n",
        "    close = df.Close\n",
        "    return 100 * (0.4 * (close.pct_change(q1, fill_method=None))\n",
        "         + 0.2 * (close.pct_change(q2, fill_method=None))\n",
        "         + 0.2 * close.pct_change(q3, fill_method=None)\n",
        "          + 0.2 * close.pct_change(q4, fill_method=None))\n",
        "\n",
        "\n",
        "def get_relative_strength(df, interval):\n",
        "    length = len(df)\n",
        "    if interval == \"Daily\":\n",
        "        if length > 252:\n",
        "            params = (63, 126, 189, 252)\n",
        "        elif length > 100:\n",
        "            params = np.linspace(0, length-1, 5, dtype=int).tolist()[1:]\n",
        "        else:\n",
        "            params = (63, 126, 189, 252)\n",
        "    elif (interval == \"Daily\") and (len(df) <= 252):\n",
        "        params = np.linspace(0, len(df) - 1, 5, dtype=int)[1:]\n",
        "    elif (interval == \"Weekly\") and (len(df) > 52):\n",
        "        params = np.linspace(0, len(df) - 1, 5, dtype=int)[1:]\n",
        "    elif (interval == \"Weekly\") and (len(df) <= 52):\n",
        "        params = (13, 26, 39, 52)\n",
        "    else:\n",
        "        params = (3, 6, 9, 12)\n",
        "\n",
        "    return _relative_strength(df, *params)\n"
      ],
      "metadata": {
        "id": "eTmvwOKJSE74"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tickers =read_ticker_file(\"screener_result.csv\")\n",
        "tickers[\"コード\"] = tickers[\"コード\"].astype(str)\n",
        "ticker_lst = tickers[\"コード\"].to_list()\n",
        "\n",
        "jpx = pd.read_excel(\"https://www.jpx.co.jp/markets/statistics-equities/misc/tvdivq0000001vg2-att/data_j.xls\")\n",
        "jpx[\"コード\"] = jpx[\"コード\"].astype(str)\n",
        "jpx = jpx[[\"コード\", \"銘柄名\", \"市場・商品区分\", \"33業種区分\", \"17業種区分\", \"規模区分\"]]"
      ],
      "metadata": {
        "id": "NNIvI2bsSGAq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start=dt.date(2009, 1, 1)\n",
        "topix = pdr.DataReader(\"^TPX\", start=start, data_source=\"stooq\").sort_index()\n",
        "topix.to_csv(\"./data/topix.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "wwZvmKASSWJS",
        "outputId": "b690a395-da96-446a-99f2-d94d9e8a2e2e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Cannot save file into a non-existent directory: 'data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7c8c21ccc7a4>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2009\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtopix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"^TPX\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_source\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"stooq\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtopix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/topix.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3900\u001b[0m         )\n\u001b[1;32m   3901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3902\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3903\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3904\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         )\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data'"
          ]
        }
      ]
    }
  ]
}